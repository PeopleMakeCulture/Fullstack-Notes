Fullstack-Hardware-Fundamentals
[Link to Video]: https://www.youtube.com/watch?v=5pmSAEeMsfo&feature=youtu.be

1. Information Theory and Hardware

	- Information theory defines information as symbols that represent things
	- Bool
	- Logic gates
	- Claude Shannon - father of information theory (US)
	- Charles Babbage & Ada Lovelace (England, 19th C.)- "difference engine" was first mechanical  computing machine
	- Modern computers use electric vs mechanical switches
		- 'signal becomes action' [eg switching on a lightbulb]
	VN Architecture (underpins all modern PCs)
		- Arithemtic Logic Unit (ALU) within CPU which takes input and produces output; linked to memory
		- CPU = control until and ALU
	- Hopper - Magnetic Tape Storage; Compilers
	- Random Access Memory (RAM) vs Hard Disk Drive (HDD)
		- Flash memory (not persistant?)
		- Floating gate transisters (Solid State Drives)
	- Hard Drive is Storage - where we keep information, but not where we do things(comuptations) with it
	- If CPU = brain ('metal'), memory is closer than storage
	- analogy: storage : file cabinet :: memory : desk
	- RAM is sweet spot between speed and space

2. Representations and Encodings

	- IEEE 754 Floating Point Signed Double
	- Float = Floating point number, with 11 bits for saying where the point should go; 52 bits for number
	- Number weirdness:
		- 1/10 is impossible to represent as decimal in binary (like 1/3 in base ten)
		- That's why math sometimes gets weird at really small values - the last bit is off by a rounding error
	- Hexadecimal 
		- 16 spaces 0-9 and a-f
		- Useful b/c every hexadecimal symbol is equivalent to a 4-digit binary symbol
	- Images can be encoded
	- Sounds can be encoded

3. Abstractions and Langauges (1:03)



4. Abstract Data Types & Structures
	1. Queues
	2. Linked Lists
	3. Hash Tables
	4. Trees
5. Extras